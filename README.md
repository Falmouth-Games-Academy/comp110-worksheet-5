# comp110-worksheet-C
Base repository for COMP110 worksheet C

a) the task is checking to see whether or not any elements are duplicated
b) as they are both nested lists checking one element in list i compared to every element in list j if there was only one duplicate at the end of i with the end of j would be worst case scenario 

c) because its starting at the same position and will terminate earlier 
d) its approximately twice as fast as averaging out the checks to only checking once
e) yes its its the same check just more efficient 
f)  sort
    O(n log n)
    O(n log n)
https://wiki.python.org/moin/TimeComplexity

g) it will only care about the dominate factor, and it would scrap the n and just use O(n log n)

h) sort will be faster on bigger data as n2 would be faster on smaller samples but as the list grows larger the time take grows a lot whereas the sort list will speed up after its sorted

i) the slower algorithms would be easier to implement than a faster more complicated algorithm

